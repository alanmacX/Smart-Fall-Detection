
# Smart Fall Detection System (YOLO + Pose + LLM + GUI)

This project implements an intelligent fall detection system combining YOLOv8 for object detection, YOLOv8-Pose for skeleton visualization, and TinyLLaMA for local natural language feedback. It includes a lightweight GUI for user-friendly interaction.

---

## ðŸ”§ Features

- **Fall detection** using custom-trained YOLOv8
- **Pose overlay** with YOLOv8-Pose (non-intrusive, only for visualization)
- **Speed calculation** and **sliding window voting** for robust fall judgment
- **Structured fall data output**, including:
  - Bounding box location
  - Movement speed
  - Fall type (sustained / sudden)
- **LLM feedback** with prompt engineering: sends structured data to TinyLLaMA to generate care advice
- **Popup feedback** displayed in GUI
- **User-friendly interface** to load videos and run detection

---

## ðŸ“ Project Structure

```
fall-detection/
â”œâ”€â”€ main.py             # Main fall detection + pose + logic + LLM output
â”œâ”€â”€ gui.py              # Tkinter GUI, handles file input and video display
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ README.md           # This file
â”œâ”€â”€ .gitignore          # Ignoring large files like .pt/.mp4
â””â”€â”€ models/             # Store model weights here (not pushed to Git)
```

---

## ðŸ’» Installation

### 1. Clone the repo:

```bash
git clone https://github.com/your-username/fall-detection.git
cd fall-detection
```

### 2. Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ðŸ“¦ Download Required Models (Manual)

| File               | Purpose                 | Link |
|--------------------|--------------------------|------|
| `best.pt`          | Trained fall detector    | *(Upload your link here)* |
| `yolov8x-pose.pt`  | Pose estimation model    | [YOLOv8 Releases](https://github.com/ultralytics/ultralytics/releases) |
| `tinyllama.gguf`   | Local LLM weights        | [TinyLLaMA on HuggingFace](https://huggingface.co/cmp-nct/tiny-llama-1.1B-gguf) |

ðŸ—‚ï¸? Place them in the `models/` directory:

```
fall-detection/
â””â”€â”€ models/
    â”œâ”€â”€ best.pt
    â”œâ”€â”€ yolov8x-pose.pt
    â””â”€â”€ tinyllama.gguf
```

---

## ðŸš€ Usage

### Start the GUI:

```bash
python gui.py
```

Then in the GUI:

1. Click â€œImport Videoâ€?
2. Click â€œStart Detectionâ€?
3. See detection + pose + fall feedback
4. Pop-up windows give real-time care suggestions based on LLM interpretation

---

## ðŸ?? LLM Setup (TinyLLaMA)

1. Install llama-cpp-python:

```bash
pip install llama-cpp-python
```

2. Make sure `tinyllama.gguf` is in `models/`
3. `llm_utils.py` uses structured fall data to send prompts and parse replies

Prompt format example:

```text
A person has fallen near the center of the video frame at a speed of 2.3.
Give a one-sentence first-aid suggestion.
```

---

## ðŸ§ª Example Screenshot

> You can insert your own demo frame here.

```
[screenshot coming soon]
```

---

## âš™ï¸ Notes

- All model files (`.pt`, `.gguf`, `.mp4`) are ignored in `.gitignore`
- This system is designed to run fully offline
- Ideal for eldercare AI system prototyping

---

## ðŸ“œ License

MIT License. Free for academic and personal use.


---

## ðŸ‹ï¸? Model Training

To train your own fall detection model using YOLOv8, follow these steps:

### 1. Prepare your dataset

Organize your data in YOLO format:

```
fall-dataset/
â”œâ”€â”€ images/
â”?   â”œâ”€â”€ train/
â”?   â””â”€â”€ val/
â”œâ”€â”€ labels/
â”?   â”œâ”€â”€ train/
â”?   â””â”€â”€ val/
â””â”€â”€ data.yaml
```

The `data.yaml` should contain:

```yaml
train: path/to/images/train
val: path/to/images/val
nc: 2
names: ["normal", "fall"]
```

> Ensure that 0 = normal, 1 = fall.

---

### 2. Run training command:

```bash
yolo task=detect mode=train model=yolov8n.pt data=data.yaml epochs=50 imgsz=640
```

You can also resume or use your own pretrained weight:

```bash
yolo task=detect mode=train model=models/best.pt data=data.yaml epochs=50 imgsz=640 resume=True
```

---

### 3. After training

- Best weights will be saved to `runs/detect/train/weights/best.pt`
- Replace the detection model in `main.py` with your new path if needed.
