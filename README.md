# Smart Fall Detection System

## ğŸ“– Project Overview

This project presents an intelligent fall detection system that integrates computer vision with large language models (LLMs), designed for elderly home safety monitoring. The system utilizes YOLOv8 for fall detection, YOLOv8-Pose for pose visualization, and incorporates TinyLLaMA to provide personalized care advice.

### ğŸ¯ Key Features

- **ğŸ” Intelligent Detection**: High-precision fall detection powered by a self-trained YOLOv8 model  
- **ğŸ¨ Pose Visualization**: Visualizes human skeleton keypoints using YOLOv8-Pose  
- **âš¡ Motion Analysis**: Calculates motion speed and applies a sliding window voting mechanism for enhanced robustness  
- **ğŸ“Š Structured Output**: Includes bounding box positions, motion speeds, fall types, etc.  
- **ğŸ¤– Smart Feedback**: Integrates TinyLLaMA to generate personalized caregiving suggestions  
- **ğŸ’» Multi-Interface Support**: Available as a desktop GUI and a web application  
- **ğŸ”’ Privacy Protection**: Local inference, no data is uploaded to the cloud  

### ğŸ—ï¸ Project Structure

```
Smart-Fall-Detection-Demo/
â”œâ”€â”€ main.py                 # Core detection logic + LLM analysis
â”œâ”€â”€ gui.py                  # Tkinter-based desktop GUI
â”œâ”€â”€ train.py                # YOLO training script
â”œâ”€â”€ data.yaml               # Dataset configuration
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ é¡¹ç›®æƒ…å†µ.txt            # Project details (Chinese)
â”œâ”€â”€ models/                 
â”‚   â”œâ”€â”€ best.pt            # Self-trained fall detection model
â”‚   â”œâ”€â”€ yolov8n-pose.pt    # Pose detection model
â”‚   â”œâ”€â”€ yolov8n.pt         # Base YOLO model
â”‚   â””â”€â”€ tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf  # LLaMA model
â”œâ”€â”€ outputs/                # Output directory for results
â”‚   â””â”€â”€ output_*.mp4       # Processed video files
â”œâ”€â”€ web_fall_detection/     # Full-featured web application
â”‚   â”œâ”€â”€ app.py             # Flask backend
â”‚   â”œâ”€â”€ requirements.txt   # Web version dependencies
â”‚   â”œâ”€â”€ README.md          # Web usage instructions
â”‚   â”œâ”€â”€ demo.mp4           # Demo video
â”‚   â”œâ”€â”€ static/            
â”‚   â”‚   â”œâ”€â”€ css/          
â”‚   â”‚   â”œâ”€â”€ js/           
â”‚   â”‚   â”œâ”€â”€ uploads/      
â”‚   â”‚   â””â”€â”€ outputs/      
â”‚   â”œâ”€â”€ templates/         
â”‚   â”‚   â”œâ”€â”€ index.html    
â”‚   â”‚   â”œâ”€â”€ result.html   
â”‚   â”‚   â””â”€â”€ test_upload.html  
â”‚   â””â”€â”€ utils/             
â”‚       â”œâ”€â”€ detector.py    
â”‚       â”œâ”€â”€ analyzer.py    
â”‚       â”œâ”€â”€ demo.py        
â”‚       â””â”€â”€ video_converter.py  
â””â”€â”€ static/                 
    â””â”€â”€ css/               
```

## ğŸš€ Quick Start

### 1. Environment Setup

#### Clone the repository
```bash
git clone https://github.com/alanmacX/Smart-Fall-Detection-Demo.git
cd Smart-Fall-Detection-Demo
```

#### Install dependencies
```bash
# For desktop version
pip install -r requirements.txt

# For web version
cd web_fall_detection
pip install -r requirements.txt
```

### 2. Download Models

| Model File | Purpose | Download Link | Size |
|------------|---------|---------------|------|
| `best.pt` | Fall detection | *Contact the author* | ~6MB |
| `yolov8n-pose.pt` | Pose estimation | [YOLOv8 Releases](https://github.com/ultralytics/ultralytics/releases) | ~6MB |
| `tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf` | LLM inference | [HuggingFace](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0) | ~0.6GB |

Place all model files in the `models/` directory.

### 3. Usage

#### ğŸ–¥ï¸ Desktop Version (GUI)
```bash
python gui.py
```
1. Click "Import Video" to upload a video  
2. Select the model file paths  
3. Click "Start Detection" to begin  
4. View detection results and LLM analysis in real-time

#### ğŸŒ Web Version (Recommended)
```bash
cd web_fall_detection
python app.py
```
Then visit `http://localhost:5000`

Web version includes:
- ğŸ“± Responsive design (mobile-friendly)
- ğŸ“Š Statistical visualizations
- ğŸ¬ In-browser video playback
- ğŸ“ˆ Performance monitoring
- ğŸ”„ Demo mode (no models required)

## ğŸ› ï¸ Model Training

### Data Preparation
```bash
dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/     
â”‚   â””â”€â”€ val/       
â””â”€â”€ labels/
    â”œâ”€â”€ train/     
    â””â”€â”€ val/       
```

### Training Config
Edit `data.yaml`:
```yaml
path: ./dataset
train: images/train
val: images/val
nc: 2
names: ["normal", "fall"]
```

### Start Training
```bash
python train.py
# Or via CLI
yolo task=detect mode=train model=yolov8n.pt data=data.yaml epochs=100 imgsz=640
```

## ğŸ¯ Technical Highlights

### Detection Logic
- **Fall Type Recognition**: Detects both sudden and sustained falls  
- **Multi-Verification Mechanism**:  
  - Sliding window voting (30 frames, threshold: 10)  
  - Speed threshold (>20 pixels/frame)  
  - Vertical displacement (>15 pixels drop)  
- **Anti-Interference Design**: Reduces false positives, improves reliability

### Performance Optimizations
- **Frame Skipping**: Configurable skip-frames in web version for speed  
- **GPU Acceleration**: Automatically detects and utilizes GPU  
- **Memory Optimization**: Smart caching to reduce memory usage  
- **Concurrent Processing**: Supports multi-task inference  

### LLM Integration
- **Offline Inference**: Works without internet, ensuring privacy  
- **Structured Input**: Converts detection output into structured LLM input  
- **Personalized Advice**: Custom caregiving suggestions based on fall patterns  
- **Multilingual Support**: Supports both English and Chinese output  

## ğŸ“Š System Performance

### Detection Accuracy
- **Precision**: >95% (based on self-trained dataset)  
- **Recall**: >90% (reduces missed falls)  
- **Inference Speed**: 30â€“60 FPS (GPU) / 10â€“20 FPS (CPU)

### System Requirements
- **CPU**: Intel i5+ or AMD Ryzen 5+  
- **RAM**: 8GB+ (16GB recommended)  
- **GPU**: Optional, NVIDIA GTX 1060+ recommended  
- **Storage**: 2GB+ (for models & dependencies)

## ğŸ”§ Configuration Options

### Detection Parameters
```python
WINDOW_SIZE = 30
VOTE_THRESHOLD = 10
SPEED_THRESHOLD = 20
CONFIDENCE_THRESHOLD = 0.5
```

### Web Performance Settings
```python
PERFORMANCE_CONFIG = {
    'use_gpu': True,
    'skip_frames': 5,
    'detection_conf': 0.6,
    'iou_threshold': 0.3
}
```

## ğŸŒŸ Use Cases

- **ğŸ  Home Care**: Monitoring elderly living alone  
- **ğŸ¥ Medical Facilities**: Patient fall prevention in wards  
- **ğŸ¢ Nursing Homes**: Large-scale safety systems  
- **ğŸ”¬ Academic Research**: For CV and AI studies  
- **ğŸ’¼ Commercial**: Smart security integration  

## ğŸ¤ Contribution Guide

Feel free to submit Issues or Pull Requests!

### Development Setup
```bash
pip install -r requirements.txt
pip install pytest black

pytest tests/

black *.py
```

## ğŸ“„ License

MIT License â€“ Free for academic and personal use

## ğŸ™ Acknowledgments

- **YOLOv8**: Thanks to the Ultralytics team  
- **TinyLLaMA**: Efficient and lightweight LLM  
- **OpenCV**: Powerful computer vision toolkit  
- **Flask**: Minimal yet powerful web framework  

## ğŸ“ Contact

- **Author**: alanmacX  
- **GitHub**: [Smart-Fall-Detection-Demo](https://github.com/alanmacX/Smart-Fall-Detection-Demo)  
- **Email**: *Contact via GitHub*

## ğŸ”„ Changelog

### v2.0.0 (2024)
- âœ… Added web version with online support  
- âœ… Integrated LLaMA for intelligent feedback  
- âœ… Improved performance with GPU acceleration  
- âœ… Expanded documentation and usage guides  

### v1.0.0 (Initial Release)
- âœ… Basic fall detection functionality  
- âœ… Tkinter GUI interface  
- âœ… YOLO model training support  

---

**â­ If you find this project helpful, please give it a Star!**
