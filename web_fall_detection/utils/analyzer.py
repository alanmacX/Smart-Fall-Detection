"""
ç»“æœåˆ†æå™¨ - åˆ†ææ£€æµ‹ç»“æœå¹¶ç”Ÿæˆå¯è§†åŒ–æ•°æ®
"""

import json
import numpy as np
from datetime import datetime, timedelta
from collections import Counter

class ResultAnalyzer:
    def __init__(self):
        self.risk_levels = {
            'low': {'min_falls': 0, 'max_falls': 1, 'color': '#28a745'},
            'medium': {'min_falls': 2, 'max_falls': 4, 'color': '#ffc107'},
            'high': {'min_falls': 5, 'max_falls': float('inf'), 'color': '#dc3545'}
        }
    
    def analyze_detection_result(self, detection_result):
        """
        åˆ†ææ£€æµ‹ç»“æœå¹¶ç”Ÿæˆç»Ÿè®¡æ•°æ®
        
        Args:
            detection_result: æ£€æµ‹ç»“æœå­—å…¸
            
        Returns:
            dict: åˆ†æç»“æœ
        """
        fall_events = detection_result.get('fall_events', [])
        video_info = detection_result.get('video_info', {})
        
        if not fall_events:
            return self._generate_no_fall_analysis(video_info)
        
        # åŸºç¡€ç»Ÿè®¡
        total_falls = len(fall_events)
        fall_types = [event['type'] for event in fall_events]
        type_counts = Counter(fall_types)
        
        # æ—¶é—´åˆ†æ
        timestamps = [event['timestamp'] for event in fall_events]
        time_analysis = self._analyze_time_distribution(timestamps, video_info.get('duration', 0))
        
        # ç½®ä¿¡åº¦åˆ†æ
        confidences = [event['confidence'] for event in fall_events]
        confidence_analysis = self._analyze_confidence(confidences)
        
        # é£é™©è¯„ä¼°
        risk_level = self._assess_risk_level(total_falls, confidences)
        
        # ç”Ÿæˆå›¾è¡¨æ•°æ®
        chart_data = self._generate_chart_data(fall_events, video_info)
        
        # ç”Ÿæˆå»ºè®®
        recommendations = self._generate_recommendations(risk_level, total_falls, fall_types)
        
        return {
            'summary': {
                'total_falls': total_falls,
                'risk_level': risk_level,
                'processing_time': detection_result.get('processing_time', 0),
                'video_duration': video_info.get('duration', 0)
            },
            'fall_types': {
                'sustained': type_counts.get('sustained', 0),
                'sudden': type_counts.get('sudden', 0),
                'distribution': dict(type_counts)
            },
            'time_analysis': time_analysis,
            'confidence_analysis': confidence_analysis,
            'chart_data': chart_data,
            'recommendations': recommendations,
            'timeline': self._generate_timeline(fall_events)
        }
    
    def _generate_no_fall_analysis(self, video_info):
        """ç”Ÿæˆæ— è·Œå€’äº‹ä»¶çš„åˆ†æç»“æœ"""
        return {
            'summary': {
                'total_falls': 0,
                'risk_level': 'low',
                'processing_time': 0,
                'video_duration': video_info.get('duration', 0)
            },
            'fall_types': {
                'sustained': 0,
                'sudden': 0,
                'distribution': {}
            },
            'time_analysis': {
                'peak_hours': [],
                'distribution': []
            },
            'confidence_analysis': {
                'average': 0,
                'max': 0,
                'min': 0,
                'distribution': []
            },
            'chart_data': {
                'timeline': [],
                'confidence_trend': [],
                'risk_heatmap': []
            },
            'recommendations': [
                "âœ… è§†é¢‘ä¸­æœªæ£€æµ‹åˆ°è·Œå€’äº‹ä»¶",
                "ğŸ“Š æ´»åŠ¨çŠ¶æ€æ­£å¸¸",
                "ğŸ” å»ºè®®å®šæœŸæ£€æŸ¥ä»¥ç¡®ä¿å±…å®¶å®‰å…¨"
            ],
            'timeline': []
        }
    
    def _analyze_time_distribution(self, timestamps, duration):
        """åˆ†ææ—¶é—´åˆ†å¸ƒ"""
        if not timestamps:
            return {'peak_hours': [], 'distribution': []}
        
        # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºå°æ—¶
        hours = [int((ts % 86400) // 3600) for ts in timestamps]
        hour_counts = Counter(hours)
        
        # æ‰¾å‡ºé«˜å³°æ—¶æ®µ
        peak_hours = [hour for hour, count in hour_counts.most_common(3)]
        
        # ç”Ÿæˆ24å°æ—¶åˆ†å¸ƒæ•°æ®
        distribution = [{'hour': h, 'count': hour_counts.get(h, 0)} for h in range(24)]
        
        return {
            'peak_hours': peak_hours,
            'distribution': distribution,
            'total_duration_minutes': duration / 60
        }
    
    def _analyze_confidence(self, confidences):
        """åˆ†æç½®ä¿¡åº¦"""
        if not confidences:
            return {'average': 0, 'max': 0, 'min': 0, 'distribution': []}
        
        # åŸºç¡€ç»Ÿè®¡
        avg_conf = np.mean(confidences)
        max_conf = np.max(confidences)
        min_conf = np.min(confidences)
        
        # ç½®ä¿¡åº¦åˆ†å¸ƒï¼ˆåˆ†ä¸º5ä¸ªåŒºé—´ï¼‰
        bins = np.linspace(0, 1, 6)
        hist, _ = np.histogram(confidences, bins=bins)
        
        distribution = []
        for i in range(len(bins)-1):
            distribution.append({
                'range': f"{bins[i]:.1f}-{bins[i+1]:.1f}",
                'count': int(hist[i])
            })
        
        return {
            'average': float(avg_conf),
            'max': float(max_conf),
            'min': float(min_conf),
            'distribution': distribution
        }
    
    def _assess_risk_level(self, total_falls, confidences):
        """è¯„ä¼°é£é™©ç­‰çº§"""
        if total_falls == 0:
            return 'low'
        
        # åŸºäºè·Œå€’æ¬¡æ•°
        for level, criteria in self.risk_levels.items():
            if criteria['min_falls'] <= total_falls <= criteria['max_falls']:
                base_level = level
                break
        else:
            base_level = 'high'
        
        # åŸºäºç½®ä¿¡åº¦è°ƒæ•´
        if confidences:
            avg_confidence = np.mean(confidences)
            if avg_confidence > 0.8 and base_level == 'low':
                return 'medium'
            elif avg_confidence > 0.9 and base_level == 'medium':
                return 'high'
        
        return base_level
    
    def _generate_chart_data(self, fall_events, video_info):
        """ç”Ÿæˆå›¾è¡¨æ•°æ®"""
        if not fall_events:
            return {'timeline': [], 'confidence_trend': [], 'risk_heatmap': []}
        
        # æ—¶é—´è½´æ•°æ®
        timeline_data = []
        for event in fall_events:
            timeline_data.append({
                'timestamp': event['timestamp'],
                'frame': event['frame'],
                'confidence': event['confidence'],
                'type': event['type']
            })
        
        # ç½®ä¿¡åº¦è¶‹åŠ¿
        confidence_trend = []
        for i, event in enumerate(fall_events):
            confidence_trend.append({
                'x': i + 1,
                'y': event['confidence'],
                'type': event['type']
            })
        
        # é£é™©çƒ­åŠ›å›¾ï¼ˆæŒ‰æ—¶é—´åˆ†æ®µï¼‰
        duration = video_info.get('duration', 0)
        if duration > 0:
            segment_count = max(1, min(20, int(duration // 30)))  # æ¯30ç§’ä¸€ä¸ªåˆ†æ®µï¼Œæœ€å¤š20ä¸ªï¼Œè‡³å°‘1ä¸ª
            segment_duration = duration / segment_count
            
            risk_heatmap = []
            for i in range(segment_count):
                start_time = i * segment_duration
                end_time = (i + 1) * segment_duration
                
                # è®¡ç®—è¯¥æ—¶é—´æ®µå†…çš„è·Œå€’äº‹ä»¶æ•°
                events_in_segment = [
                    e for e in fall_events 
                    if start_time <= e['timestamp'] < end_time
                ]
                
                risk_level = len(events_in_segment)
                risk_heatmap.append({
                    'segment': i,
                    'start_time': start_time,
                    'end_time': end_time,
                    'risk_level': risk_level,
                    'events': len(events_in_segment)
                })
        else:
            risk_heatmap = []
        
        return {
            'timeline': timeline_data,
            'confidence_trend': confidence_trend,
            'risk_heatmap': risk_heatmap
        }
    
    def _generate_recommendations(self, risk_level, total_falls, fall_types):
        """ç”Ÿæˆæ™ºèƒ½å…³æ€€å»ºè®®"""
        recommendations = []
        
        # åŸºç¡€é£é™©è¯„ä¼°å»ºè®®
        if risk_level == 'low':
            recommendations.extend([
                "âœ… æ•´ä½“é£é™©è¾ƒä½ï¼ŒçŠ¶æ€è‰¯å¥½",
                "ğŸ” å»ºè®®ä¿æŒå®šæœŸè§‚å¯Ÿå’Œé¢„é˜²æ€§æ£€æŸ¥",
                "ï¿½ å¯è€ƒè™‘é€‚é‡è¿åŠ¨ä»¥å¢å¼ºèº«ä½“å¹³è¡¡èƒ½åŠ›",
                "ğŸ  å®šæœŸæ£€æŸ¥å±…ä½ç¯å¢ƒï¼Œæ¶ˆé™¤æ½œåœ¨å®‰å…¨éšæ‚£"
            ])
        elif risk_level == 'medium':
            recommendations.extend([
                "âš ï¸ æ£€æµ‹åˆ°ä¸­ç­‰é£é™©ï¼Œéœ€è¦å¢åŠ å…³æ³¨åº¦",
                "ğŸ‘¥ å»ºè®®å®¶å±æˆ–æŠ¤ç†äººå‘˜å¢åŠ æ¢è®¿å’Œç…§æ–™é¢‘ç‡",
                "ğŸ¥ å»ºè®®å’¨è¯¢åŒ»ç–—ä¸“ä¸šäººå‘˜ï¼Œè¿›è¡Œå¥åº·è¯„ä¼°",
                "ğŸ›¡ï¸ ç«‹å³åŠ å¼ºå±…å®¶å®‰å…¨æªæ–½ï¼Œå®‰è£…å¿…è¦çš„è¾…åŠ©è®¾å¤‡",
                "ğŸ“± è€ƒè™‘ä½¿ç”¨ç´§æ€¥å‘¼å«æˆ–ç›‘æŠ¤è®¾å¤‡"
            ])
        else:  # high
            recommendations.extend([
                "ğŸš¨ æ£€æµ‹åˆ°é«˜é£é™©æƒ…å†µï¼Œéœ€è¦ç«‹å³é‡‡å–è¡ŒåŠ¨",
                "ğŸ“ å»ºè®®ç«‹å³è”ç³»å®¶å±ã€æŠ¤ç†äººå‘˜æˆ–ç´§æ€¥è”ç³»äºº",
                "ğŸ¥ å¼ºçƒˆå»ºè®®å°½å¿«å¯»æ±‚ä¸“ä¸šåŒ»ç–—å¸®åŠ©å’Œè¯„ä¼°",
                "ğŸ‘¨â€âš•ï¸ è€ƒè™‘å®‰æ’ä¸“ä¸šæŠ¤ç†äººå‘˜æˆ–å¢åŠ å®¶å±é™ªæŠ¤",
                "ğŸ›¡ï¸ ç«‹å³å…¨é¢æ”¹å–„å±…ä½ç¯å¢ƒå®‰å…¨é…ç½®",
                "ğŸš‘ å¿…è¦æ—¶è€ƒè™‘ç´§æ€¥åŒ»ç–—å¹²é¢„"
            ])
        
        # åŸºäºè·Œå€’ç±»å‹çš„ä¸“é¡¹å»ºè®®
        type_counter = Counter(fall_types)
        
        if type_counter.get('sudden', 0) > 0:
            sudden_count = type_counter['sudden']
            recommendations.extend([
                f"âš¡ æ£€æµ‹åˆ°{sudden_count}æ¬¡çªå‘æ€§è·Œå€’ï¼Œå¯èƒ½çš„åŸå› å’Œå»ºè®®ï¼š",
                "   â€¢ å¯èƒ½ä¸å¹³è¡¡åè°ƒã€è¡€å‹æ³¢åŠ¨æˆ–è¯ç‰©å‰¯ä½œç”¨æœ‰å…³",
                "   â€¢ å»ºè®®è¿›è¡Œç¥ç»ç³»ç»Ÿå’Œå¿ƒè¡€ç®¡åŠŸèƒ½æ£€æŸ¥",
                "   â€¢ è¯„ä¼°å½“å‰æœç”¨è¯ç‰©æ˜¯å¦å½±å“å¹³è¡¡èƒ½åŠ›",
                "   â€¢ å¢åŠ å¹³è¡¡è®­ç»ƒå’Œåè°ƒæ€§é”»ç‚¼"
            ])
            
        if type_counter.get('sustained', 0) > 0:
            sustained_count = type_counter['sustained']
            recommendations.extend([
                f"ğŸ• æ£€æµ‹åˆ°{sustained_count}æ¬¡æŒç»­æ€§è·Œå€’ï¼Œå¯èƒ½çš„åŸå› å’Œå»ºè®®ï¼š",
                "   â€¢ å¯èƒ½ä¸è‚ŒåŠ›ä¸è¶³ã€å…³èŠ‚é—®é¢˜æˆ–èµ·èº«å›°éš¾æœ‰å…³",
                "   â€¢ å»ºè®®è¿›è¡Œè‚ŒåŠ›å’Œå…³èŠ‚åŠŸèƒ½è¯„ä¼°",
                "   â€¢ è€ƒè™‘ä½¿ç”¨è¾…åŠ©èµ·èº«è®¾å¤‡ï¼ˆå¦‚åºŠè¾¹æ‰¶æ‰‹ã€èµ·èº«æ¤…ï¼‰",
                "   â€¢ å®‰æ’ç‰©ç†æ²»ç–—æˆ–åº·å¤è®­ç»ƒä»¥æ”¹å–„æ´»åŠ¨èƒ½åŠ›"
            ])
        
        # ç¯å¢ƒå®‰å…¨å»ºè®®
        recommendations.append("ğŸ  å±…ä½ç¯å¢ƒå®‰å…¨ä¼˜åŒ–å»ºè®®ï¼š")
        if risk_level == 'low':
            recommendations.extend([
                "   â€¢ å®šæœŸæ£€æŸ¥åœ°é¢æ˜¯å¦æœ‰æ¾æ•£åœ°æ¯¯æˆ–éšœç¢ç‰©",
                "   â€¢ ç¡®ä¿å„æˆ¿é—´ç…§æ˜å……è¶³ï¼Œç‰¹åˆ«æ˜¯å¤œé—´ç…§æ˜",
                "   â€¢ ä¿æŒå¸¸ç”¨ç‰©å“æ”¾ç½®åœ¨å®¹æ˜“å–å¾—çš„é«˜åº¦"
            ])
        else:
            recommendations.extend([
                "   â€¢ ç«‹å³ç§»é™¤æ‰€æœ‰åœ°é¢éšœç¢ç‰©å’Œæ¾æ•£åœ°æ¯¯",
                "   â€¢ åœ¨å«ç”Ÿé—´ã€æ¥¼æ¢¯å’Œèµ°å»Šå®‰è£…æ‰¶æ‰‹",
                "   â€¢ å®‰è£…é˜²æ»‘å«ï¼Œç‰¹åˆ«æ˜¯æµ´å®¤å’Œå¨æˆ¿åŒºåŸŸ",
                "   â€¢ æ”¹å–„ç…§æ˜ç³»ç»Ÿï¼Œå®‰è£…å¤œç¯å’Œæ„Ÿåº”ç¯",
                "   â€¢ å°†æ—¥å¸¸ç”¨å“æ”¾ç½®åœ¨è…°éƒ¨é«˜åº¦ï¼Œé¿å…å¼¯è…°æˆ–è¸®è„š"
            ])
        
        # å¥åº·ç›‘æŠ¤å»ºè®®
        recommendations.append("ğŸ“Š å¥åº·ç›‘æŠ¤å’Œéšè®¿å»ºè®®ï¼š")
        if total_falls <= 1:
            recommendations.extend([
                "   â€¢ å»ºè®®æ¯æœˆè¿›è¡Œä¸€æ¬¡å®‰å…¨è‡ªæŸ¥",
                "   â€¢ ä¿æŒå®šæœŸä½“æ£€ï¼Œå…³æ³¨å¹³è¡¡å’Œåè°ƒèƒ½åŠ›",
                "   â€¢ è®°å½•æ—¥å¸¸æ´»åŠ¨çŠ¶å†µï¼Œå‘ç°å¼‚å¸¸åŠæ—¶å°±åŒ»"
            ])
        elif total_falls <= 3:
            recommendations.extend([
                "   â€¢ å»ºè®®æ¯å‘¨è¿›è¡Œå®‰å…¨è¯„ä¼°å’Œç›‘æŠ¤",
                "   â€¢ å®‰æ’å®šæœŸåŒ»ç–—æ£€æŸ¥ï¼ŒåŒ…æ‹¬è§†åŠ›ã€å¬åŠ›å’Œå¹³è¡¡æµ‹è¯•",
                "   â€¢ å»ºç«‹è·Œå€’æ—¥å¿—ï¼Œè®°å½•å¯èƒ½çš„è¯±å‘å› ç´ ",
                "   â€¢ è€ƒè™‘ä½¿ç”¨å¯ç©¿æˆ´è®¾å¤‡è¿›è¡Œæ—¥å¸¸ç›‘æµ‹"
            ])
        else:
            recommendations.extend([
                "   â€¢ éœ€è¦æ¯æ—¥ä¸“ä¸šç›‘æŠ¤å’Œå®‰å…¨è¯„ä¼°",
                "   â€¢ å®‰æ’ç´§æ€¥åŒ»ç–—è¯„ä¼°å’Œåç»­æ²»ç–—è®¡åˆ’",
                "   â€¢ å»ºç«‹24å°æ—¶ç´§æ€¥è”ç³»å’Œå“åº”æœºåˆ¶",
                "   â€¢ è€ƒè™‘çŸ­æœŸä½é™¢è§‚å¯Ÿæˆ–ä¸“ä¸šæŠ¤ç†æœºæ„ç…§æ–™"
            ])
        
        return recommendations
    
    def _generate_timeline(self, fall_events):
        """ç”Ÿæˆäº‹ä»¶æ—¶é—´è½´"""
        timeline = []
        for i, event in enumerate(fall_events):
            minutes = int(event['timestamp'] // 60)
            seconds = int(event['timestamp'] % 60)
            
            timeline.append({
                'id': i + 1,
                'time': f"{minutes:02d}:{seconds:02d}",
                'timestamp': event['timestamp'],
                'type': event['type'],
                'confidence': event['confidence'],
                'frame': event['frame'],
                'description': f"ç¬¬{i+1}æ¬¡è·Œå€’äº‹ä»¶ ({event['type']}ç±»å‹)"
            })
        
        return timeline
